
Lifelogging - Curation
----------------------

Author: Michael Gravina  
Revision: 171229  
Effective date: 12/29/2017  



# Purpose

This protocol describes practices for curating the Lifelogging data after it has been
collected and archived. The purpose of curation is to select a set of stimuli for 
the Lifelogging experiments from the un-curated archive.  


# Assignment of responsibilities

A principal operator should be assigned to set up and manage the Lifelogging data for
each given study group.

Subject IDs:__________________________________   

Operator(s):  
Name______________________________ Init______   Name______________________________ Init______  


# Required equipment and supplies

 - Access to the Borg server  


# Methods and procedures

## Curation scheme for image sets

<br><br>

 - Verify that there is, natively, a uniform sampling across the days of collection in the archive.
It is expected that a day or two may be omitted for subject-specific reasons, and some days may have
sparser data than others. However, if there are long runs of days with no data or many half-days with
very little data, this should be noted in the study record and consideration of these irregularities
should be made when constructing the curated stimuli set (see below).  

<br><br>

 - Exclude:
    - Any image which is too dark or blurry to clearly identify.  
    - Uninteresting images taken right up against walls, ceilings, floors, etc.  
    - Reflections of the subjects themselves.   

<br><br>

 - Now try to pick out as many distinct episodes in each basic time unit (a half-day by default) as
possible.  
    - **The definition of an "episode"** will be somewhat arbitrary. An easy case would be a subject who
travels regularly between clearly different locations to do markedly different things; a hard
case would be a subject who stays in one place for the majority of the time, who spends long
periods doing the same thing (such as using computers or mobile phones), or who constantly
travels without stopping.
In these harder cases, episodes can be defined by transitions to new activities, a shift of
the people the subject is interacting with, movements between smaller sub-sections of the same
setting, etc.  
    - **Try to select episodes fairly evenly across both time and space**. If there is a very
rich interval at the beginning of a time period, you may be tempted to get all the episodes you need from
that interval and neglect the rest of the period. Avoid this if possible, and select at least some
episodes from later in the period. By the same token, if a single spatial setting dominates a time
period, try to include at least a few other locations if possible rather than taking all episodes from
that one setting.  
    - **Exercise judgement** in all of this. Try to follow the guidelines above to the best of
your ability, but when in doubt, it's better to err on the side of ommission. For some very short
or uniform time periods, you may just have to accept a less-than-desired number of episodes or
even none at all. Don't duplicate obviously alike images just to "fill out" the number of episodes
in a given time period or create even coverage where none really exists.    
When a fixed number of episodes are called for in the experimental design, you can correct for such gaps
by selecting a number of extra episodes equal to the shortfall, evenly distributed across the other
time-periods. For instance, for a subject with good data on most days but 2 days with no usable episodes,
and a requirement to try to pick 5 episodes each day, you would choose no episodes from those 2 days
and spread an additional 10 episodes as evenly as possible across the remaining days.  

   

<br>

  - **Replication of PNAS paper:**
      - 21 days x 8 images per day (4 in the morning, 4 in the afternoon) = 168 images total
      - Randomize the images.
      - We do not want a time-block of time much greater than 7 minutes. Half a block of 84 images takes about 7.5 minutes. 4 time-blocks will exhaust all 168 images and take about 30 minutes.
      - **File structure:**<br>
        All image files should be collected into the same "images" folder within each SMILE experiment. This folder can be assembled from a folder structure of the sort used in Meredith's experiment (see below) using the  `grabImagesIntoOneFolder.py` script.
    - **File preprocessing:**<br>
        The `resizeImages.py` script should be used to resize all images to a standard height of 500 pixels (enter `python resizeImages.py folder` where `folder` is the directory containing all of the collected images for the experiment). Do this on the curated copies, NOT on the original images in the non-curated folders.

<br>

  - **Meredith's experiment:**
<br><br>
     - Select images to balance across the following bins:
         1. Which image is more recent (first or second image, 2 conditions)
         2. Gap between images (6 conditions), "logarithmically" spaced:
             - Within-morning/evening, between morning and evening, 1-2 days, 4-6 days, 8-12 days, 7 days (to explore cyclical patterns)
             - Max gap of half experimental duration to avoid compound with bin set #1
             - Includes at least a pair from each day to sample the supposed “temporal fovea”
         3. Recency of the most recent (proximal and distal, for 3 conditions)
            - Logarithmically spaced
<br><br>
    - The above will yield 36 different conditions (2 order x 6 gap x 3 recency). Include 2 of each condition in each block of 72 image pairs. At ~5s per trial/pair, that is 6 minutes per block. Running 4 blocks will take ~24 minutes.
    - In the event that subjects are missing data for specific days, images should be pulled evenly from the remaining days in order to make up for the shortfall.
    - **File structure:**<br>
        The curated image files should be sorted into folders by day (named in format 'subj00X_dayXX', where XX is the left-zero-padded day of the study, starting at 01), and within each day folder into subfolders named 'morning' and 'afternoon'.
    - **File preprocessing:**<br>
        The `resizeImages.py` script should be used to resize all images to a standard height of 500 pixels (enter `python resizeImages.py folder` where `folder` is the directory containing the 21 day-level folders). Do this on the curated copies, NOT on the original images in the non-curated folders.































 - **Common to all experiments:**
     - Verify that there is, natively, a uniform sampling across days in the archive (try and visualize the distribution of timestamps in Python)
     - Pick out as many distinct episodes from the morning and afternoon of each day for each subject. At least 30 per day, 15 in the morning and 15 in the afternoon.
     - Spatial distances should be sampled as much as possible, but we expect this to fall out pretty naturally if we ensure time is evenly sampled.
     - Try and balance features - people/nopeople, inside/outside. Time and space most important. Exclude:
Floors/ceilings/walls, Reflections of the subjects

     - Do not repeat photos
   

<br>

  - **Replication of PNAS paper:**
      - 21 days x 8 images per day (4 in the morning, 4 in the afternoon) = 168 images total
      - Randomize the images.
      - We do not want a time-block of time much greater than 7 minutes. Half a block of 84 images takes about 7.5 minutes. 4 time-blocks will exhaust all 168 images and take about 30 minutes.
      - **File structure:**<br>
        All image files should be collected into the same "images" folder within each SMILE experiment. This folder can be assembled from a folder structure of the sort used in Meredith's experiment (see below) using the  `grabImagesIntoOneFolder.py` script.
    - **File preprocessing:**<br>
        The `resizeImages.py` script should be used to resize all images to a standard height of 500 pixels (enter `python resizeImages.py folder` where `folder` is the directory containing all of the collected images for the experiment). Do this on the curated copies, NOT on the original images in the non-curated folders.

<br>

  - **Meredith's experiment:**
<br><br>
     - Select images to balance across the following bins:
         1. Which image is more recent (first or second image, 2 conditions)
         2. Gap between images (6 conditions), "logarithmically" spaced:
             - Within-morning/evening, between morning and evening, 1-2 days, 4-6 days, 8-12 days, 7 days (to explore cyclical patterns)
             - Max gap of half experimental duration to avoid compound with bin set #1
             - Includes at least a pair from each day to sample the supposed “temporal fovea”
         3. Recency of the most recent (proximal and distal, for 3 conditions)
            - Logarithmically spaced
<br><br>
    - The above will yield 36 different conditions (2 order x 6 gap x 3 recency). Include 2 of each condition in each block of 72 image pairs. At ~5s per trial/pair, that is 6 minutes per block. Running 4 blocks will take ~24 minutes.
    - In the event that subjects are missing data for specific days, images should be pulled evenly from the remaining days in order to make up for the shortfall.
    - **File structure:**<br>
        The curated image files should be sorted into folders by day (named in format 'subj00X_dayXX', where XX is the left-zero-padded day of the study, starting at 01), and within each day folder into subfolders named 'morning' and 'afternoon'.
    - **File preprocessing:**<br>
        The `resizeImages.py` script should be used to resize all images to a standard height of 500 pixels (enter `python resizeImages.py folder` where `folder` is the directory containing the 21 day-level folders). Do this on the curated copies, NOT on the original images in the non-curated folders.







Equation:
$$ t_i = \rho t_{i-1} + t^{IN}, $$

Figure with a caption:
![*Example figure with caption.* Here is how to write a figure with a caption. You can insert multiple image types, including PNG and PDF. Figures will be inserted to fill the complete width of the page, though you can request a width as a percentage (see the end of the caption). The tag after the pound sign is key for referencing the figure in the text.](figs/example.png){#fig:example width=50%}

Checkboxes, fields and data-source/signature/date fields (protocols should double as records)
[  ]  
___________  
Operator_________ Date____ /____ /__________  


# Schedule of repeating tasks
[//]: # (What maintenance is required for device – how often should it be checked)


# Data retrieval
[//]: # (How to get the raw data from the device)


# Data processing
[//]: # (What software is required to download/view the data)
[//]: # (Process for getting data into Smartabase (later))


# Quality control

Deviation reporting  
Audits for patients/dat  


# Plan for electronic archiving

Data storage/security requirements  
Data entry methods  
Audits  


# IRB protocols

 - 2009B0093: Networks of Memories


# References


# Revisions

|**SOP Revision #** |**Date**       |**Description of change(s)**                          |
|-------------------|---------------|------------------------------------------------------|
|171229             |12/29/2017     |First version                                         |


[//]: # (Invisible comment)
